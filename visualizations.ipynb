{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469a297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391129c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "fake_news_df = pd.read_csv('data/fake_news.csv', usecols=range(4))\n",
    "real_news_df = pd.read_csv('data/real_news.csv', usecols=range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d96823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column that will combine all columns to help determine fake and real news; this data will be used to train our model\n",
    "fake_news_df['combined_text'] = fake_news_df['title'] + ' ' + fake_news_df['text']\n",
    "real_news_df['combined_text'] = real_news_df['title'] + ' ' + real_news_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7d8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "wordcloud_words_fake = []\n",
    "\n",
    "# Tokenize lemmatized words for wordcloud_words_fake\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for index, row in fake_news_df.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = row['combined_text']\n",
    "    # Convert to lower case\n",
    "    sentence = sentence.lower()\n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]+', '', sentence)\n",
    "    # Cleaning the sentence with regex\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Stopwords removal / lemmatize\n",
    "    wordcloud_words_fake = [str(w) for w in words if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e781ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_words_real = []\n",
    "\n",
    "# Tokenize lemmatized words for wordcloud_words_real\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for index, row in real_news_df.iterrows():\n",
    "    filter_sentence = ''\n",
    "    sentence = row['combined_text']\n",
    "    # Convert to lower case\n",
    "    sentence = sentence.lower()\n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]+', '', sentence)\n",
    "    # Cleaning the sentence with regex\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    # Tokenization\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    # Stopwords removal / lemmatize\n",
    "    wordcloud_words_real = [str(w) for w in words if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e367c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_fake_news_df = pd.DataFrame(wordcloud_words_fake, columns=['Words'])\n",
    "wordcloud_fake_news_df['Count'] = 1\n",
    "\n",
    "wordcloud_real_news_df = pd.DataFrame(wordcloud_words_real, columns=['Words'])\n",
    "wordcloud_real_news_df['Count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7793e34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>navy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sailors</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>held</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>st</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>century</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>wire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>iran</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>files</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Words  Count\n",
       "0         us      1\n",
       "1       navy      1\n",
       "2    sailors      1\n",
       "3       held      1\n",
       "4    iranian      1\n",
       "..       ...    ...\n",
       "513       st      1\n",
       "514  century      1\n",
       "515     wire      1\n",
       "516     iran      1\n",
       "517    files      1\n",
       "\n",
       "[518 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcloud_fake_news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_fake_news_df = wordcloud_fake_news_df.groupby('Words')\n",
    "wordcloud_fake_news_df = wordcloud_fake_news_df.agg({\"Count\": \"sum\"})\n",
    "\n",
    "wordcloud_fake_news = wordcloud_fake_news_df.sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a30dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f561d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_fake_news_df.to_csv('research.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41070243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b07787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique list of words\n",
    "unique_wordcloud_words_fake = pd.unique(wordcloud_words_fake)\n",
    "unique_wordcloud_words_real = pd.unique(wordcloud_words_real)\n",
    "\n",
    "# Combine all words into one big string\n",
    "wordcloud_words_fake = \" \".join(word for word in unique_wordcloud_words_fake)\n",
    "wordcloud_words_real = \" \".join(word for word in unique_wordcloud_words_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ea550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1facd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba557a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8630072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to swap numbers 0 to 255 (white)\n",
    "def transform_format(val):\n",
    "    if val == 0:\n",
    "        return 255\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b907332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PNG mask\n",
    "mask = np.array(Image.open(\".static/images/magnifying_glass.png\"))\n",
    "    \n",
    "# Transform mask\n",
    "transformed_mask = np.ndarray((mask.shape[0],mask.shape[1]), np.int32)\n",
    "\n",
    "# for i in range(len(mask)):\n",
    "#     transformed_mask[i] = list(map(transform_format, mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud image\n",
    "wc = WordCloud(background_color=\"white\", max_words=1000, mask=transformed_mask,\n",
    "               contour_width=3, contour_color='black')\n",
    "\n",
    "# Generate a wordcloud\n",
    "wc.generate(word_cloud_text)\n",
    "\n",
    "# Store to file\n",
    "wc.to_file(\"Images/word_cloud.png\")\n",
    "\n",
    "# Show\n",
    "plt.figure(figsize=[20,10])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
